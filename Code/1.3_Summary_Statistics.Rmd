---
title: "Probability and statistics with R for Data Science"
author: "Luca Pennella"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dslabs)

```

### **Summary Statistics**

We will explore the concepts needed to understand distributions and how they relate to summary statistics. To make this easier, let's imagine we have to describe the heights of our classmates to an extraterrestrial (ET) who has never seen humans. To do this, we first need to collect some data.

### **Step 1: Collecting Data**

We ask students to report their heights in inches and provide their sex (male or female) since we know height distributions can vary by sex. We will use the `heights` dataset included in the **dslabs** package.

```{r,eval=TRUE}
# Load the dslabs package to access the heights dataset
library(dslabs)
```

### **Step 2: Conveying Heights to ET**

One way to convey this information to ET is by sending the list of heights directly. However, there are more efficient methods, and understanding the concept of a distribution can help. 

To simplify, we will first focus on the heights of males. We will look at female heights later.

In some situations, the **average** and the **standard deviation** of the data can provide a good summary. We will learn data visualization techniques to determine when this two-number summary is sufficient and when more information is needed.

### **Understanding Variable Types**

We will work with two types of variables:

1. **Categorical Variables**: Data divided into categories or groups.
   - Example: Sex (Male, Female), US regions (Northeast, South, etc.).
   - **Ordinal** categorical data: Ordered categories (e.g., spiciness levels: mild, medium, hot).

2. **Numeric Variables**: Data that are numbers.
   - Example: Heights, population sizes, murder rates.
   - **Discrete**: Numbers that are counts (e.g., number of gun murders).
   - **Continuous**: Numbers that can take any value (e.g., height with high precision).

It's important to note that **discrete numeric data** can sometimes be considered ordinal. For instance, the number of packs of cigarettes a person smokes per day (rounded to the nearest pack) can be considered ordinal. However, the actual number of cigarettes smoked is typically treated as a numerical variable.

### **Basic Statistical Summary: Distribution**

The most basic statistical summary of a list of numbers or objects is called its **distribution**. This is a compact description of a list with many entries.

- For **categorical data**, the distribution describes the proportion of each unique category.

Here is an example using US state regions:

```{r,eval=TRUE}
# Calculate and display the proportion of each US state region
prop.table(table(state.region))
```

- For **numerical data**, summarizing the distribution is more complex. We will introduce a motivating problem to help understand these concepts better.


### **Empirical Cumulative Distribution Functions (eCDF)**

When dealing with numerical data, defining a distribution can be challenging because most values are unique, making frequency reporting less effective. For instance, in our height data, while a few students reported a height of 68 inches, other students reported unique heights like 68.503937007874 inches or 68.8976377952756 inches, likely converted from 174 and 175 centimeters.

#### **Defining the eCDF**

To summarize numeric data distributions more effectively, statistics introduces the **empirical cumulative distribution function (eCDF)**. This function, denoted by \( F(a) \), represents the proportion of data points that are less than or equal to a specific value \( a \).

The eCDF is defined as:

$$ F(a) = \text{Proportion of data points that are less than or equal to } a $$

#### **Plotting the eCDF for Male Heights**

Here’s how you can plot the eCDF for male heights:

```{r,eval=TRUE}
# Filter the data to include only male heights and plot the eCDF
heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) + 
  stat_ecdf() + 
  labs(x = "a", y = "F(a)")
```

- **`stat_ecdf()`**: This function plots the eCDF by calculating the cumulative distribution for the given data.
- **`aes(height)`**: This maps the height variable to the x-axis.
- **`labs(x = "a", y = "F(a)")`**: Labels the axes as \(a\) and \(F(a)\).

This plot shows the cumulative distribution of male heights, indicating the proportion of heights below specific values. For example, from the plot, we can determine that a certain percentage of the male students are shorter than 66 inches, and a different percentage is shorter than 72 inches.


### **Histograms**

Though the eCDF is useful, it's not the most popular tool in practice because it doesn’t clearly show where the data is centered, whether it's symmetric, or which ranges contain most of the values. Instead, **histograms** are often preferred for summarizing numerical data.

#### **Creating a Histogram**

A histogram divides the range of data into equal-sized intervals (bins) and counts the number of data points in each bin. These counts are then plotted as bars.

Here’s how to create a histogram for male heights:

```{r,eval=TRUE}
# Create a histogram of male heights with 1-inch bins
heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) + 
  geom_histogram(binwidth = 1, color = "black")
```

- **`geom_histogram(binwidth = 1, color = "black")`**: This function creates the histogram, setting each bin to cover 1 inch, and the bars are outlined in black.
- **`binwidth = 1`**: Specifies that each bin should cover a 1-inch interval.

#### **Interpreting the Histogram**

The histogram is similar to a bar plot but with a numerical x-axis. From this plot, we can quickly learn several important features of the data:

1. **Range**: Heights vary from 50 to 84 inches.
2. **Center**: Heights are centered around 69 inches.
3. **Symmetry**: The distribution is nearly symmetric around 69 inches.
4. **Majority Range**: Over 95% of the heights fall between 63 and 75 inches.

While the histogram summarizes the data effectively, it does lose some detailed information. For example, all heights within each bin are treated the same, so slight differences between values like 64, 64.1, and 64.2 inches are ignored. However, these small details are often negligible, allowing us to summarize the data with much fewer numbers.


### **Smoothed Density Plots**

A **smoothed density plot** is an alternative to histograms for visualizing the distribution of numerical data. Unlike histograms, where data is divided into discrete bins, smoothed density plots provide a continuous estimate of the distribution, giving a more fluid representation of data.

Here’s how you can create a smoothed density plot for male heights:

```{r,eval=TRUE}
# Create a smoothed density plot for male heights
heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) + 
  geom_density(alpha = 0.2, fill = "#00BFC4")
```

- **`geom_density()`**: This function generates the smoothed density plot.
- **`alpha = 0.2`**: Sets the transparency level of the filled area under the curve.
- **`fill = "#00BFC4"`**: Colors the area under the curve.

In this plot, the sharp edges present in histograms are replaced by a smooth curve, and the y-axis represents *density* rather than counts.

To grasp the idea of smoothed densities, it helps to think in terms of a large hypothetical dataset. Imagine that the heights of male students we have represent a small sample from a much larger population. Suppose we had one million such height measurements, then we could create a histogram with very fine bins. This histogram would appear smooth, with minimal differences in height between adjacent bins.

#### **Simulating the Smoothness with a Histogram**

We can simulate this concept by creating histograms with smaller and smaller bin sizes:

```{r,eval=TRUE}
# Simulate a large dataset and create histograms with different bin widths
set.seed(1988)
x <- data.frame(height = c(rnorm(1000000,69,3), rnorm(1000000,65,3)))

# Histogram with bin width of 1 inch
p1 <- x |> ggplot(aes(height)) + geom_histogram(binwidth = 1) + ggtitle("binwidth = 1")

# Histogram with bin width of 0.5 inch
p2 <- x |> ggplot(aes(height)) + geom_histogram(binwidth = 0.5) + ggtitle("binwidth = 0.5")

# Histogram with bin width of 0.1 inch
p3 <- x |> ggplot(aes(height)) + geom_histogram(binwidth = 0.1) + ggtitle("binwidth = 0.1")

library(gridExtra)
grid.arrange(p1, p2, p3, nrow = 1)
```

As the bin width decreases, the histogram becomes smoother. The smooth density plot essentially draws a curve through the tops of these histogram bars if the bins were infinitely small.

#### **Linking Smoothed Density to Frequency**

In practice, we don’t have millions of data points, so we create a density curve based on the available data. This curve is computed on frequencies rather than raw counts, allowing for a more generalized view of the distribution.

Here’s how we transition from a histogram to a smoothed density:

```{r,eval=TRUE}
# Create a histogram and overlay a density curve
hist1 <- heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, color = "black")

# Add the smooth density curve to the histogram
hist2 <- hist1 + geom_line(stat = 'density')

# Plot various steps leading to the smoothed density
hist3 <- hist1 + geom_point(data = ggplot_build(hist2)$data[[1]], aes(x,y), col = "blue")
hist4 <- ggplot() + geom_point(data = ggplot_build(hist2)$data[[1]], aes(x,y), col = "blue") + 
  xlab("height") + ylab("density")
hist5 <- hist4 + geom_line(data = ggplot_build(hist2)$data[[2]], aes(x,y))

# Final smooth density plot
hist6 <- heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) +
  geom_density(alpha = 0.2, fill="#00BFC4", col = 0) +
  geom_line(stat = 'density') +
  scale_y_continuous(limits = layer_scales(hist2)$y$range$range)

grid.arrange(hist1, hist3, hist4, hist5, hist2, hist6, nrow = 2)
```

#### **Adjusting Smoothness**

The smoothness of the density curve can be adjusted using the `adjust` parameter in the `geom_density()` function. Different levels of smoothness can lead to different interpretations of the data:

```{r,eval=TRUE}
# Smoothed density plots with different degrees of smoothness
p <- heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 1, alpha = 0.5) 

p1 <- p + geom_line(stat = 'density', adjust = 0.5)  # Less smooth
p2 <- p + geom_line(stat = 'density', adjust = 2)    # More smooth

grid.arrange(p1, p2, ncol = 2)
```

When selecting the degree of smoothness, choose a level that accurately represents the data without introducing unnecessary noise or oversmoothing.

#### **Interpreting the Y-Axis in Density Plots**

The y-axis in a smoothed density plot is scaled so that the area under the curve equals 1. This allows for comparing distributions, but interpreting specific values requires considering the area under the curve. For instance, to find the proportion of male students with heights between 65 and 68 inches, we can calculate the area under the curve in this range:

```{r,eval=TRUE}
# Calculate and plot the area under the curve between 65 and 68 inches
d <- with(heights, density(height[sex == "Male"]))
tmp <- data.frame(height = d$x, density = d$y)

tmp |> ggplot(aes(height, density)) + 
  geom_line() + 
  geom_area(aes(x = height, y = density), data = filter(tmp, between(height, 65, 68)), alpha = 0.2, fill = "#00BFC4")
```

The area under the curve in this range represents the proportion of male students with heights between 65 and 68 inches.


Smoothed density plots provide a powerful way to visualize the distribution of data, offering a continuous representation that can reveal underlying patterns. However, the smoothness must be chosen carefully, and the y-axis interpretation requires understanding that the total area under the curve equals 1. 


### **The Normal Distribution**

The normal distribution, or Gaussian distribution, is a cornerstone of statistics due to its prevalence in many natural phenomena like heights, blood pressure, test scores, and more. It is known for its symmetrical bell-shaped curve.

#### **Defining the Normal Distribution**

Unlike histograms or density plots derived from data, the normal distribution is defined mathematically, allowing us to estimate the proportion of values within any interval \((a, b)\) using the following formula:

$$\mbox{Pr}(a < x \leq b) = \int_a^b \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}\left( \frac{x-\mu}{\sigma} \right)^2} \, dx$$

Here, \(\mu\) (mean) and \(\sigma\) (standard deviation) completely define the distribution, while \(a\) and \(b\) are the limits of the interval. The constants \(\pi\) and \(e\) are mathematical constants involved in the formula.

#### **Characteristics of the Normal Distribution**

- **Symmetry**: The curve is symmetric around the mean \(\mu\).
- **Spread**: The spread of data is controlled by the standard deviation \(\sigma\), with about 95% of the data within two standard deviations from the mean.

#### **Visualizing the Normal Distribution**

To visualize a normal distribution with mean 0 and standard deviation 1:

```{r,eval=TRUE}
# Define mean and standard deviation
m <- 0; s <- 1

# Create a sequence of values for x and calculate their corresponding density values
norm_dist <- data.frame(x = seq(-4, 4, len = 50)*s + m) |> 
  mutate(density = dnorm(x, m, s))

# Plot the normal distribution
norm_dist |> ggplot(aes(x, density)) + geom_line()
```

#### **Calculating Mean and Standard Deviation**

For a numeric vector `x`, the mean and standard deviation are calculated as follows:

```{r,eval=TRUE}
# Calculate mean
m <- sum(x) / length(x)

# Calculate standard deviation
s <- sqrt(sum((x - m)^2) / length(x))
```

The standard deviation is essentially the average distance of the data points from their mean.

#### **Using Pre-built Functions**

Instead of manually calculating, you can use built-in functions:

```{r,eval=TRUE}
# Assume x contains the heights of male students
index <- heights$sex == "Male"
x <- heights$height[index]

# Calculate mean and standard deviation using built-in functions
m <- mean(x)
s <- sd(x)
```

::: callout-warning
The `sd()` function in R uses \( n-1 \) in the denominator (Bessel's correction), which corrects bias in the estimation of the population variance from a sample. However, for large sample sizes, this adjustment has minimal effect on the value of the standard deviation.
:::

#### **Comparing Student Heights with the Normal Distribution**

Finally, let’s compare the smooth density of student heights with the normal distribution:

```{r,eval=TRUE}
# Define the sequence for the normal distribution based on the calculated mean and SD
norm_dist <- data.frame(x = seq(-4, 4, len = 50)*s + m) |> 
  mutate(density = dnorm(x, m, s))

# Plot the smooth density of heights and overlay the normal distribution
heights |> filter(sex == "Male") |> ggplot(aes(height)) +
  geom_density(fill = "#00BFC4") +
  geom_line(aes(x, density),  data = norm_dist)
```

This plot demonstrates how the normal distribution serves as an approximation for the data. The close fit between the empirical data and the theoretical model illustrates the usefulness of the normal distribution in summarizing and understanding data distributions.


The normal distribution provides a powerful tool for summarizing data through its mean and standard deviation. By understanding this distribution, we can make predictions about data and better understand its underlying patterns.

#### **Standard Units**

Standard units are a way of normalizing data. They convert raw scores into a scale where the mean is 0 and the standard deviation is 1. This transformation is useful because it allows us to compare different datasets on the same scale and understand data points in terms of their deviation from the mean.

**Calculation of Standard Units**:
For any value `x` from a vector `X`, the standard unit `z` is calculated as follows:

```{r,eval=TRUE}
z = (x - m) / s
```
where `m` is the mean and `s` is the standard deviation of `X`.

This conversion is significant because it reshapes the data into a form where:
- A value of `z = 0` represents the mean.
- Values of `z = ±1` are one standard deviation from the mean.
- Values of `z = ±2` are two standard deviations from the mean, and so on.

This standardization simplifies many statistical calculations and interpretations.

**Using R to Convert to Standard Units**:

```{r,eval=TRUE}
# Convert x to standard units
z <- scale(x)

# Calculate the proportion of data within 2 standard deviations from the mean
mean(abs(z) < 2)  # Approximately 95% for normal distributions
```

#### **Quantile-Quantile Plots (QQPlots)**

QQPlots are graphical tools to compare the quantiles of two distributions. They are particularly useful for assessing whether a dataset follows a theoretical distribution, such as the normal distribution.

**Steps to Create a QQPlot**:
1. **Define Proportions**: Choose a set of proportions (e.g., 0.05, 0.1, ..., 0.95).
2. **Calculate Sample Quantiles**: Use the `quantile` function in R to get quantiles from the data corresponding to these proportions.
3. **Calculate Theoretical Quantiles**: Use the `qnorm` function to calculate the theoretical quantiles for a normal distribution with the same mean and standard deviation as the data.
4. **Plot the Quantiles**: Plot the sample quantiles against the theoretical quantiles. If the data approximates a normal distribution, the points should fall along a line.

**Example of Creating a QQPlot**:

```{r,eval=TRUE}
# Define a vector of proportions
p <- seq(0.05, 0.95, 0.05)

# Obtain sample quantiles
sample_quantiles <- quantile(x, p)

# Obtain theoretical quantiles
theoretical_quantiles <- qnorm(p, mean = mean(x), sd = sd(x))

# Plot sample quantiles against theoretical quantiles
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
```

This QQPlot helps to visualize how closely the data follows a normal distribution. If the points deviate significantly from the line, it suggests the data may not be normally distributed.

**Simplifying with Standard Units**:

Using standard units simplifies the creation of QQPlots:

```{r,eval=TRUE}
# Using standard units for QQPlot
sample_quantiles <- quantile(z, p)
theoretical_quantiles <- qnorm(p)  # Default parameters for a standard normal distribution
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
```

#### **Practical Use of QQPlots in R with ggplot2**:

In practice, using `ggplot2` makes the process straightforward:

```{r,eval=TRUE}
# Use ggplot2 to create a QQPlot for male heights in standard units
heights |> 
  filter(sex == "Male") |>
  ggplot(aes(sample = scale(height))) + 
  geom_qq() +
  geom_abline()
```

This method automatically scales the data and plots the quantiles against those of a standard normal distribution, making it easy to assess the normality of the data.


Understanding standard units and the use of QQPlots is essential for statistical analysis, especially when dealing with data that is or is assumed to be normally distributed. These tools provide a standardized way to assess and interpret data, helping to confirm theoretical assumptions about the distribution of data points.


## Percentiles

Before we move on, let's define some terms that are commonly used in exploratory data analysis.

*Percentiles* are special cases of *quantiles* that are commonly used. The percentiles are the quantiles you obtain when setting the $p$ at $0.01, 0.02, ..., 0.99$. For example, we refer to the case of $p = 0.25$ as the 25th percentile, representing a value below which 25% of the data falls. The most famous percentile is the 50th, also known as the *median*.

For the normal distribution, the *median* and average are the same, but this is generally not the case.

Another special case that receives a name are the *quartiles*, which are obtained when setting $p = 0.25,0.50$, and $0.75$.

#### **Boxplots**

Boxplots provide a five-number summary of a dataset: the minimum, first quartile (Q1), median (second quartile, Q2), third quartile (Q3), and maximum. These are effective for summarizing and comparing distributions because they highlight central tendencies and variability within the data, as well as identify outliers.

Here is how to interpret the boxplot elements:

- **The Box**: Represents the interquartile range (IQR), spanning from Q1 to Q3.
- **Whiskers**: Extend to show the range (up to 1.5 times the IQR from the box), excluding outliers.
- **Outliers**: Shown as individual points beyond the whiskers.
- **Median**: Marked by a horizontal line within the box, offering a quick sense of the distribution's symmetry and center.

#### **Stratification**

Stratification involves dividing data into subgroups (strata) based on certain variables, which allows for more targeted analysis and comparison across different segments.

**Example of Stratification and Box plot with Height Data**:

We often use stratification to compare distributions across defined groups. In your example, height data is stratified by sex:

```{r,eval=TRUE}
# Compare heights between males and females using boxplots
heights |> ggplot(aes(sex, height, fill = sex)) + geom_boxplot()
```

This comparison reveals differences in height distributions between males and females, which is crucial for accurate analysis and reporting.


## Exercises

1\. In the `murders` dataset, the region is a categorical variable and the following is its distribution:

```{r summaries-barplot-exercise, echo = FALSE}
library(dslabs)
ds_theme_set()
murders |> group_by(region) |>
  summarize(n = n()) |>
  mutate(Proportion = n/sum(n), 
         region = reorder(region, Proportion)) |>
  ggplot(aes(x = region, y = Proportion, fill = region)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  xlab("")
```

To the closest 5%, what proportion of the states are in the North Central region?

2\. Which of the following is true:

a.  The graph above is a histogram.
b.  The graph above shows only four numbers with a bar plot.
c.  Categories are not numbers, so it does not make sense to graph the distribution.
d.  The colors, not the height of the bars, describe the distribution.

3\. The plot below shows the eCDF for male heights:

```{r summaries-ecdf-exercise, echo = FALSE}
heights |> filter(sex == "Male") |> ggplot(aes(height)) + 
  stat_ecdf() +
  ylab("F(a)") + xlab("a")
```

Based on the plot, what percentage of males are shorter than 75 inches?

a.  100%
b.  95%
c.  80%
d.  72 inches

4\. To the closest inch, what height `m` has the property that 1/2 of the male students are taller than `m` and 1/2 are shorter?

a.  61 inches
b.  64 inches
c.  69 inches
d.  74 inches

5\. Here is an eCDF of the murder rates across states:

```{r summaries-ecdf-exercise-2, echo = FALSE}
murders |> mutate(murder_rate = total/population * 10^5) |>
  ggplot(aes(murder_rate)) + 
  stat_ecdf() +
  ylab("F(a)") + xlab("a")
```

Knowing that there are 51 states (counting DC) and based on this plot, how many states have murder rates larger than 10 per 100,000 people?

a.  1
b.  5
c.  10
d.  50

6\. Based on the eCDF above, which of the following statements are true:

a.  About half the states have murder rates above 7 per 100,000 and the other half below.
b.  Most states have murder rates below 2 per 100,000.
c.  All the states have murder rates above 2 per 100,000.
d.  With the exception of 4 states, the murder rates are below 5 per 100,000.

7\. Below is a histogram of male heights in our `heights` dataset:

```{r summaries-height-histogram-exercise, echo = FALSE}
heights |> 
  filter(sex == "Male") |> 
  ggplot(aes(height)) + 
  geom_histogram(binwidth = 1, color = "black")
```

Based on this plot, how many males are between 63.5 and 65.5?

a.  10
b.  24
c.  47
d.  100

8\. About what **percentage** are shorter than 60 inches?

a.  1%
b.  10%
c.  25%
d.  50%

9\. Study the following boxplots showing population sizes by country:

```{r summaries-boxplot-exercise, echo = FALSE, message = FALSE}
library(tidyverse)
library(dslabs)
ds_theme_set()
tab <- gapminder |> filter(year == 2010) |> group_by(continent) |> select(continent, population)  
tab |> ggplot(aes(x = continent, y = population/10^6)) + 
  geom_boxplot() + 
  scale_y_continuous(trans = "log10", breaks = c(1,10,100,1000)) + ylab("Population in millions")
```

Which continent has the country with the biggest population size?

10\. Which continent has the largest median population size?

11\. What is median population size for Africa to the nearest million?

12\. What proportion of countries in Europe have populations below 14 million?

a.  0.99
b.  0.75
c.  0.50
d.  0.25
